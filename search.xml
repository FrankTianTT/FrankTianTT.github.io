<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Hexo中marked和mathjax冲突的问题</title>
    <url>/2020/12/10/Hexo%E4%B8%ADmarked%E5%92%8Cmathjax%E5%86%B2%E7%AA%81%E7%9A%84%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<p>最近打算在博客上整理一些论文笔记，发现hexo默认支持的marked渲染和我附加的mathjax渲染是冲突的，主要有包括两个符号，<code>\</code>和<code>_</code>。</p>
<a id="more"></a>
<p>网上冲浪了一下找到了三种解决方案，分别是</p>
<ul>
<li>手动在<code>\</code>和<code>_</code>前面添加转义符，或者在公式前后用保护块，其实用python正则表达式替换一下也不麻烦，但是我是强迫症，放弃。</li>
<li>更改marked.js的代码，把marked处理<code>\</code>和<code>_</code>的部分去掉，留着这两个符号给mathjax处理，但是我是强迫症，放弃。</li>
<li>使用pandoc，把原来的marked卸载掉。</li>
</ul>
<p>显然最后我选择了第三种方法。</p>
<p>主要就是卸载掉原来的渲染引擎<code>npm uninstall hexo-renderer-marked</code>，并安装pandoc<code>npm install hexo-renderer-pandoc</code>。注意pandoc是需要安装在本地的，在ubuntu下用<code>apt</code>安装就好了。在Mac上还有一个坑，我在下载Anaconda的时候它自带了一个版本很久的pandoc，和Hexo使用的pandoc有冲突，需要卸载掉Anaconda自带的，然后手动去官网上安装。</p>
<p>解决问题后我又找到了NexT官方给出的解决方案<a href="https://github.com/theme-next/hexo-theme-next/blob/master/docs/zh-CN/MATH.md">数学公式</a>，不过里面有一些东西已经随着NexT本身的更新消失了。</p>
<p>总之就是非常烦😡。</p>
]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>不做程序员</tag>
        <tag>写个博客怎么这么多坑</tag>
      </tags>
  </entry>
  <entry>
    <title>建站攻略</title>
    <url>/2020/12/08/%E5%BB%BA%E7%AB%99%E6%94%BB%E7%95%A5/</url>
    <content><![CDATA[<p>让我来总结一下这个网站的主要技术。</p>
<p>总的来说，就是用Hexo在阿里云的服务器渲染网站页面，同时又把页面的提交到了github page和gitee page上，让这两个网站也可以同步我的网站。最后实现了自动pull和push的功能，让我可以在我的Mac上专注写文字，然后用一个脚本解决所有问题。</p>
<a id="more"></a>
<p>在这里我们不贴一堆乱七八糟的代码了，把主要流程和借鉴的博客贴上来好了。</p>
<p>首先是在Linux上建立Hexo，要安装nvm和Node.js，以及包管理工具npm。服务器上可能无法访问raw.githubusercontent.com，可以参考GitHub520这个项目。然后就是建立目录，初始化Hexo项目，再把NexT这个主题放到对应的目录下。随便改一改主题，挑一个自己喜欢的。然后可以把github和gitee的master分支加入Hexo的deploy配置中，而整个项目保存在dev分支中。</p>
<p>这部分主要参考<a href="https://blog.csdn.net/u010725842/article/details/80672739">Linux下使用Hexo搭建github博客</a>和<a href="https://blog.csdn.net/weixin_44555878/article/details/106588253">hexo博客部署并同步更新到服务器</a>。Hexo和NexT的用法很容易搜到。</p>
<p>此外，在阿里云中将端口号映射为二级域名可以通过<a href="https://blog.csdn.net/zz_aiytag/article/details/108868654">阿里云二级域名解析到指定端口号的一种方法</a>实现。</p>
<p>接下来在本地clone下来，写个脚本自动登陆到远程的服务器上，从gitee的dev上pull下来，然后push到github上的dev中。最后<code>hexo generate</code>和<code>hexo deploy</code>。</p>
<p>我是用的是<code>expect</code>脚本登陆服务器，<code>git pull</code>要输入密码的话也可以用<code>expect</code>脚本。<code>expect</code>脚本的教程也很好找，一个值得注意的坑是<code>expect</code>的转义字符，例如<code>$</code>是<code>\\\$</code>，详见<a href="https://blog.csdn.net/secondjanuary/article/details/21775953">expect需要转义的符号列表</a>。</p>
<p>在服务器上<code>git pull</code>可能会有冲突，可以先<code>git fetch</code>然后<code>git --hard reset gitee/dev</code>最后再<code>git pull</code>。他们的区别可以看<a href="https://www.cnblogs.com/runnerjack/p/9342362.html">git fetch &amp; pull详解</a>。</p>
<p>此外还有一些坑，例如hexo有一些依赖库要装，百度上都能搜到我就不记录了，毕竟我又不是程序员。</p>
]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>不做程序员</tag>
      </tags>
  </entry>
  <entry>
    <title>用Bellman算子理解动态规划</title>
    <url>/2020/12/10/%E7%94%A8Bellman%E7%AE%97%E5%AD%90%E7%90%86%E8%A7%A3%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/</url>
    <content><![CDATA[<p>这片文章算是对Distributional DQN的补充内容，介绍了一些value-based的基本概念以及收敛性的证明。</p>
<p>下面的内容主要是对这个<a href="https://web.stanford.edu/class/cme241/lecture_slides/BellmanOperators.pdf">slides</a>的整理。</p>
<a id="more"></a>
<h2 id="value-functions-as-vectors">Value Functions as Vectors</h2>
<p>首先，我们尝试把一个<strong>函数</strong>看作一个<strong>向量</strong>，这可能是泛函中最基本的概念。</p>
<p>我们假设在状态空间<span class="math inline">\(\mathcal{S}\)</span>中有<span class="math inline">\(n\)</span>个状态<span class="math inline">\(\left\{s_{1}, s_{2}, \dots, s_{m}\right\}\)</span></p>
<p>在动作空间<span class="math inline">\(\mathcal{A}\)</span>中有<span class="math inline">\(m\)</span>个状态<span class="math inline">\(\left\{a_{1}, a_{2}, \dots, a_{m}\right\}\)</span></p>
<p>当然在连续的情形就是<span class="math inline">\(n = \infty\)</span>或者<span class="math inline">\(m = \infty\)</span>，不过它们依旧可以表示为一系列向量。</p>
<p>我们的随机策略定义为<span class="math inline">\(\pi(a | s)\)</span>。</p>
<p>那么值函数定义为<span class="math inline">\(\mathbf{v}: \mathcal{S} \to \mathbb{R}\)</span>，当然值函数是针对某个策略<span class="math inline">\(\pi\)</span>而言的，也就是<span class="math inline">\(\mathbf{v}_{\pi}: \mathcal{S} \to \mathbb{R}\)</span>，最优值函数被定义为<span class="math inline">\(\mathbf{v}_{*}(s)=\max _{\pi} \mathbf{v}_{\pi}(s)\)</span>。</p>
<p>定义<span class="math inline">\(\mathcal{R}_{s}^{a}\)</span>是在状态<span class="math inline">\(s\)</span>做动作<span class="math inline">\(a\)</span>得到奖赏的期望。</p>
<p>定义<span class="math inline">\(\mathcal{P}_{s, s^{\prime}}^{a}\)</span>是在状态<span class="math inline">\(s\)</span>做动作<span class="math inline">\(a\)</span>到达状态<span class="math inline">\(s^\prime\)</span>的概率。</p>
<p>那么我们可以用<span class="math inline">\(\mathbf{R}_{\pi}(s)\)</span>表示对于这个策略<span class="math inline">\(\pi\)</span>，在状态<span class="math inline">\(s\)</span>下可能获得的“奖赏的期望”的期望（第一个期望来自环境的不确定性，第二个期望来自策略的不确定性）</p>
<p><span class="math display">\[\mathbf{R}_{\pi}(s)=\sum_{a \in \mathcal{A}} \pi(a | s) \cdot \mathcal{R}_{s}^{a}\]</span></p>
<p>用<span class="math inline">\(\mathbf{P}_{\pi}\left(s, s^{\prime}\right)\)</span>表示对于这个策略<span class="math inline">\(\pi\)</span>，从状态<span class="math inline">\(s\)</span>转移到状态<span class="math inline">\(s^\prime\)</span>的概率。</p>
<p><span class="math display">\[\mathbf{P}_{\pi}\left(s, s^{\prime}\right)=\sum_{a \in \mathcal{A}} \pi(a | s) \cdot \mathcal{P}_{s, s^{\prime}}^{a}\]</span></p>
<p>我们用<span class="math inline">\(\mathbf{R}_{\pi}\)</span>表示向量<span class="math inline">\(\left[\mathbf{R}_{\pi}\left(s_{1}\right), \mathbf{R}_{\pi}\left(s_{2}\right), \ldots, \mathbf{R}_{\pi}\left(s_{n}\right)\right]\)</span>，用<span class="math inline">\(\mathbf{P}_{\pi}\)</span>表示矩阵<span class="math display">\[\left[\mathbf{P}_{\pi}\left(s_{i},s_{i^{\prime}}\right)\right], 1 \leq i, i^{\prime} \leq n\]</span>.</p>
<p>定义<span class="math inline">\(\gamma\)</span>为MDP折扣因子。</p>
<h2 id="bellman-operators">Bellman Operators</h2>
<p>算子<strong>operator</strong>，可以粗浅的理解为</p>
<ul>
<li><p>函数的输入是集合，输出是集合</p></li>
<li><p>泛函的输入是函数，输出是集合</p></li>
<li><p>算子的输入是函数，输出是函数（也就是我们这篇文章考虑的情况）</p></li>
</ul>
<p><strong>Bellman Policy Operator</strong> <span class="math inline">\(\mathbf{B}_{\pi}\)</span>作为一个算子，是针对策略<span class="math inline">\(\pi\)</span>而言的，它作用于函数<span class="math inline">\(\mathbf v\)</span>之上</p>
<p><span class="math display">\[\mathbf{B}_{\pi}\mathbf{v}=\mathbf{R}_{\pi}+\gamma \mathbf{P}_{\pi} \cdot \mathbf{v}\]</span></p>
<p><span class="math inline">\(\mathbf{B}_{\pi}\)</span>是一个线性的算子，有不动点<span class="math inline">\(\mathbf v_\pi\)</span>，即<span class="math inline">\(\mathbf{B}_{\pi} \mathbf{v}_{\pi}=\mathbf{v}_{\pi}\)</span>。</p>
<p>这个不动点由<span class="math inline">\(\mathbf{B}_{\pi}\)</span>决定，<strong>本质上</strong>是由<span class="math inline">\(\mathbf{R }_{\pi}\)</span>，<span class="math inline">\(\mathbf{P}_{\pi}\)</span>和<span class="math inline">\(\gamma\)</span>决定。（也就是说给定<span class="math inline">\(\mathbf{R }_{\pi}\)</span>，<span class="math inline">\(\mathbf{P}_{\pi}\)</span>和<span class="math inline">\(\gamma\)</span>，我们就可以计算出一个<span class="math inline">\(\mathbf{v}_{\pi}\)</span>，这正是<strong>策略评估</strong>做的事情）</p>
<p>还有算子<strong>Bellman Optimality Operator</strong> <span class="math inline">\(\mathbf{B}_{*}\)</span>，被定义为</p>
<p><span class="math display">\[\left(\mathbf{B}_{*}\mathbf{v}\right)(s)=\max _{a}\left\{\mathcal{R}_{s}^{a}+\gamma \sum_{s^{\prime} \in \mathcal{S}} \mathcal{P}_{s, s^{\prime}}^{a} \cdot \mathbf{v}\left(s^{\prime}\right)\right\}\]</span></p>
<p><span class="math inline">\(\mathbf{B}_{*}\)</span>并不依赖于某个具体的策略，它是定义在一个MDP之上的。</p>
<p><span class="math inline">\(\mathbf{B}_{*}\)</span> 也有不动点<span class="math inline">\(\mathbf{v}_{*}\)</span>，满足<span class="math inline">\(\mathbf{B}_{*}\mathbf{v}_{*}=\mathbf{v}_{*}\)</span>。</p>
<p>这个不动点由<span class="math inline">\(\mathbf{B}_{*}\)</span>决定，本质上是由<span class="math inline">\(\mathcal{R}_{s}^{a}\)</span>，<span class="math inline">\(\mathcal{P}_{s, s^{\prime}}^{a}\)</span>和<span class="math inline">\(\gamma\)</span>决定。（也就是说给定$<em>{s}^{a} <span class="math inline">\(，\)</span></em>{s, s<sup>{}}</sup>{a}<span class="math inline">\(和\)</span><span class="math inline">\(，我们就可以计算出一个\)</span>_{*}$，这正是<strong>值迭代</strong>做的事情）</p>
<p>接下来我们定义一个greedy的策略<span class="math inline">\(G(\mathbf{v})(s)\)</span>，<span class="math inline">\(G\)</span>是一个算子，<strong>输入</strong>是函数<span class="math inline">\(\mathbf{v}: \mathcal{S} \to \mathbb{R}\)</span>，<strong>输出</strong>是函数<span class="math inline">\({\pi}: \mathcal{S} \to \mathcal{A}\)</span></p>
<p><span class="math display">\[G(\mathbf{v})(s)=\underset{a}{\arg \max }\left\{\mathcal{R}_{s}^{a}+\gamma \sum_{s^{\prime} \in \mathcal{S}} \mathcal{P}_{s, s^{\prime}}^{a} \cdot \mathbf{v}\left(s^{\prime}\right)\right\}\]</span></p>
<p>这意味着<span class="math inline">\(G(\mathbf{v})\)</span><strong>其实就是</strong>一个策略<span class="math inline">\(\pi\)</span>。</p>
<p>接下来，值得注意的是，对任何值函数<span class="math inline">\(\mathbf{v}\)</span>，满足（这就是<strong>策略提升</strong>做的事情）</p>
<p><span class="math display">\[\mathbf{B}_{G(\mathbf{v})}\mathbf{v}=\mathbf{B}_{*} \mathbf{v}\]</span></p>
<p>注意<span class="math inline">\(\mathbf{B}_{*} \mathbf{v}\)</span>并不一定满足<span class="math inline">\(\mathbf{B}_{*} \mathbf{v} = \mathbf{v}\)</span>，上面的式子其实就是做了<span class="math inline">\(\underset{a}{\arg \max }\)</span>和<span class="math inline">\(\underset{a}{\max }\)</span>的转换。</p>
<h2 id="contraction-and-monotonicity-of-operators">Contraction and Monotonicity of Operators</h2>
<p>接下来我们定义<span class="math inline">\(\gamma -\text{contraction operators}\)</span>，如果一个算子<span class="math inline">\(\mathbf{B}\)</span>满足，对任意两个值函数<span class="math inline">\(\mathbf v_1,\mathbf v_2\)</span>，有</p>
<p><span class="math display">\[\left\|\mathbf{B} \mathbf{v}_{1}-\mathbf{B}\mathbf{v}_{2}\right\|_{\infty} \leq \gamma\left\|\mathbf{v}_{1}-\mathbf{v}_{2}\right\|_{\infty}\]</span></p>
<p>那么我们说这个算子<span class="math inline">\(\mathbf{B}\)</span>在<span class="math inline">\(L^{\infty}\)</span>上是<span class="math inline">\(\gamma -\text{contraction operators}\)</span>的。</p>
<p>可以证明，前面的<span class="math inline">\(\mathbf{B}_{\pi}\)</span>和<span class="math inline">\(\mathbf{B}_{*}\)</span>都满足上面的性质。</p>
<p>我们可以对<strong>离散</strong>的情况做一个简单的证明，因为状态空间<span class="math inline">\(\mathcal S\)</span>是一个有限集，任何策略的值函数都可以表示为<span class="math inline">\(\mathbf v_{\pi} = \{\mathbf v_{\pi}(s_1),\mathbf v_{\pi}(s_2),\cdots,\mathbf v_{\pi}(s_n)\}\)</span></p>
<p>而策略状态转移矩阵<span class="math inline">\(\mathbf{P}_{\pi}\)</span>则是一个<span class="math inline">\(n\times n\)</span>的矩阵。</p>
<p>对于<span class="math inline">\(L^{\infty}\)</span>，一个有限向量<span class="math inline">\(\mathbf x\)</span>的<span class="math inline">\(L^{\infty}\)</span>其实就是<span class="math inline">\(\mathbf x\)</span>中最大的元素，也就是说</p>
<p><span class="math display">\[\left\|\mathbf{x}\right\|_{\infty}= \max_i \mathbf x_i\]</span></p>
<p>实际上，把<span class="math inline">\(\mathbf x\)</span>看作一个集合，<span class="math inline">\(L^{\infty}\)</span>就是在衡量这个集合的<strong>直径</strong>。</p>
<p>接下来，我们根据上面的说明做一个简单的证明。</p>
<p>对于Bellman Policy Operator <span class="math inline">\(\mathbf{B}_{\pi}\)</span>，有</p>
<p><span class="math display">\[\begin{aligned}   \left\|\mathbf{B}_{\pi} \mathbf{v}_{1}-\mathbf{B}_{\pi} \mathbf{v}_{2}\right\|_{\infty}&amp;=\left\| \mathbf{R}_{\pi}+\gamma \mathbf{P}_{\pi} \cdot \mathbf{v_1} -  \mathbf{R}_{\pi}+\gamma \mathbf{P}_{\pi} \cdot \mathbf{v_2}\right\|_{\infty}  \\     &amp;=\left\| \gamma \mathbf{P}_{\pi} \cdot \mathbf{v_1} - \gamma \mathbf{P}_{\pi} \cdot \mathbf{v_2}\right\|_{\infty}  \\     &amp;=\gamma \left\|  \mathbf{P}_{\pi} \cdot (\mathbf{v_1} - \mathbf{v_2})\right\|_{\infty}  \\     &amp;=\gamma  \max _i\mathbf{P}_{\pi} \cdot (\mathbf{v_1} - \mathbf{v_2})_i\\     &amp; \leq \gamma  \max _i (\mathbf{v_1} - \mathbf{v_2})_i \\     &amp; =\gamma\left\|\mathbf{v}_{1}-\mathbf{v}_{2}\right\|_{\infty}\\  \end{aligned}\]</span></p>
<p>中间那个小于等于号很显然，是因为<span class="math inline">\(\mathbf{P}_{\pi}\)</span>是一个状态转移矩阵，每行的值都小于<span class="math inline">\(1\)</span>，而合等于<span class="math inline">\(1\)</span>，也就是说乘上<span class="math inline">\(\mathbf{P}_{\pi}\)</span>相当于做了一次加权平均，自然不会让变得更大。</p>
<p>对于Bellman Optimality Operator <span class="math inline">\(\mathbf{B}_{*}\)</span>，我们先说明<span class="math inline">\(\mathbf{B}_{*} \mathbf{v}\)</span>的形式，在<span class="math inline">\(\mathbf{v}\)</span>是有限集的情况下，<span class="math inline">\(\mathbf{B}_{*} \mathbf{v}\)</span>可以被表示成一个向量</p>
<p><span class="math display">\[\mathbf{B}_{*} \mathbf{v} = \left(\max _{a}\left\{\mathcal{R}_{s _1}^{a}+\gamma \sum_{s^{\prime} \in \mathcal{S}} \mathcal{P}_{s_1, s^{\prime}}^{a} \cdot \mathbf{v}\left(s^{\prime}\right)\right\}, \\ \max _{a}\left\{\mathcal{R}_{s_2}^{a}+\gamma \sum_{s^{\prime} \in \mathcal{S}} \mathcal{P}_{s_2, s^{\prime}}^{a} \cdot \mathbf{v}\left(s^{\prime}\right)\right\},\\ \cdots\\ \max _{a}\left\{\mathcal{R}_{s_n}^{a}+\gamma \sum_{s^{\prime} \in \mathcal{S}} \mathcal{P}_{s_n, s^{\prime}}^{a} \cdot \mathbf{v}\left(s^{\prime}\right)\right\}\right)\]</span></p>
<p>那么对于<span class="math inline">\(\mathbf{B}_{*} \mathbf{v_1} - \mathbf{B}_{*} \mathbf{v_2}\)</span>，有</p>
<p><span class="math display">\[\mathbf{B}_{*}\mathbf{v_1}  - \mathbf{B}_{*} \mathbf{v_2}  =\\ \left(\max _{a}\left\{\mathcal{R}_{s _1}^{a}+\gamma \sum_{s^{\prime} \in \mathcal{S}} \mathcal{P}_{s_1, s^{\prime}}^{a} \cdot \mathbf{v_1}\left(s^{\prime}\right)\right\} - \max _{a}\left\{\mathcal{R}_{s _1}^{a}+\gamma \sum_{s^{\prime} \in \mathcal{S}} \mathcal{P}_{s_1, s^{\prime}}^{a} \cdot \mathbf{v_2}\left(s^{\prime}\right)\right\}, \\  \max _{a}\left\{\mathcal{R}_{s_2}^{a}+\gamma \sum_{s^{\prime} \in \mathcal{S}} \mathcal{P}_{s_2, s^{\prime}}^{a} \cdot \mathbf{v_1}\left(s^{\prime}\right)\right\}-\max _{a}\left\{\mathcal{R}_{s_2}^{a}+\gamma \sum_{s^{\prime} \in \mathcal{S}} \mathcal{P}_{s_2, s^{\prime}}^{a} \cdot \mathbf{v_2}\left(s^{\prime}\right)\right\},\\ \cdots\\ \max _{a}\left\{\mathcal{R}_{s_n}^{a}+\gamma \sum_{s^{\prime} \in \mathcal{S}} \mathcal{P}_{s_n, s^{\prime}}^{a} \cdot \mathbf{v_1}\left(s^{\prime}\right)\right\}-\max _{a}\left\{\mathcal{R}_{s_n}^{a}+\gamma \sum_{s^{\prime} \in \mathcal{S}} \mathcal{P}_{s_n, s^{\prime}}^{a} \cdot \mathbf{v_2}\left(s^{\prime}\right)\right\}\right)\]</span></p>
<p>注意，实际上<span class="math inline">\(\max_a\)</span>可以看作对一个长度为<span class="math inline">\(|\mathcal A |\)</span>的向量用<span class="math inline">\(L^{\infty}\)</span>，也就是<span class="math inline">\(\max_a\)</span>满足三角不等式，于是，对于<span class="math inline">\(\mathbf{B}_{*} \mathbf{v_1} - \mathbf{B}_{*} \mathbf{v_2}\)</span>的每一个元素，有</p>
<p><span class="math display">\[\begin{aligned}     &amp;\max _{a}\left\{\mathcal{R}_{s_n}^{a}+\gamma \sum_{s^{\prime} \in \mathcal{S}} \mathcal{P}_{s_n, s^{\prime}}^{a} \cdot \mathbf{v_1}\left(s^{\prime}\right)\right\}-\max _{a}\left\{\mathcal{R}_{s_n}^{a}+\gamma \sum_{s^{\prime} \in \mathcal{S}} \mathcal{P}_{s_n, s^{\prime}}^{a} \cdot \mathbf{v_2}\left(s^{\prime}\right)\right\}  \\     &amp;\leq \max _{a}\left\{\mathcal{R}_{s_n}^{a}+\gamma \sum_{s^{\prime} \in \mathcal{S}} \mathcal{P}_{s_n, s^{\prime}}^{a} \cdot \mathbf{v_1}\left(s^{\prime}\right)-\mathcal{R}_{s_n}^{a}+\gamma \sum_{s^{\prime} \in \mathcal{S}} \mathcal{P}_{s_n, s^{\prime}}^{a} \cdot \mathbf{v_2}\left(s^{\prime}\right)\right\}\\     &amp;=\gamma \max _{a}\left\{\sum_{s^{\prime} \in \mathcal{S}} \mathcal{P}_{s_n, s^{\prime}}^{a} \cdot \left( \mathbf{v_1}\left(s^{\prime}\right)-\mathbf{v_2}\left(s^{\prime}\right) \right)\right\}\\   \end{aligned}\]</span></p>
<p>同时，无论怎样选择<span class="math inline">\(a\)</span>，<span class="math inline">\(\mathcal{P}_{s, s^{\prime}}^{a}\)</span>都是一个概率转移矩阵，和<span class="math inline">\(\mathbf{P}_{\pi}\)</span>有类似的特点，相当于取加权，于是同理得到</p>
<p><span class="math display">\[\left\|\mathbf{B}_{*} \mathbf{v}_{1}-\mathbf{B}_{*} \mathbf{v}_{2}\right\|_{\infty} \leq \gamma\left\|\mathbf{v}_{1}-\mathbf{v}_{2}\right\|_{\infty}\]</span></p>
<p>证明了<span class="math inline">\(\mathbf{B}_{\pi}\)</span>和<span class="math inline">\(\mathbf{B}_{*}\)</span>都是<span class="math inline">\(\gamma -\text{contraction operators}\)</span>，由<strong>Contraction Mapping​ Theorem</strong>，我们可以得到<span class="math inline">\(\mathbf{B}_{\pi}\)</span>和<span class="math inline">\(\mathbf{B}_{*}\)</span>都含有唯一的不动点。</p>
<p>接下来，我们定义值函数之间的小于，如果<span class="math inline">\(\mathbf{v}_{1}\leq \mathbf{v}_{2}\)</span>，意味着对于所有的<span class="math inline">\(s\)</span>满足</p>
<p><span class="math display">\[\mathbf{v}_{1}(s)\leq \mathbf{v}_{2}(s)\]</span></p>
<p>不难证明</p>
<p><span class="math display">\[\begin{array}{l} \mathbf{v}_{1} \leq \mathbf{v}_{2} \to \mathbf{B}_{\pi} \mathbf{v}_{1} \leq \mathbf{B}_{\pi} \mathbf{v}_{2} \\ \mathbf{v}_{1} \leq \mathbf{v}_{2} \to \mathbf{B}_{*} \mathbf{v}_{1} \leq \mathbf{B}_{*} \mathbf{v}_{2}  \end{array}\]</span></p>
<p>也就是说<span class="math inline">\(\mathbf{B}_{\pi}\)</span>和<span class="math inline">\(\mathbf{B}_{*}\)</span>都是单调的。</p>
<h2 id="policy-evaluation">Policy Evaluation</h2>
<p>有了上面的推导，我们就可以很直观的看待策略评估的过程了。</p>
<p>对于任何策略<span class="math inline">\(\pi\)</span>，我们可以得到<span class="math inline">\(\mathbf{B}_{\pi}\)</span>，那么策略评估就是在找到<span class="math inline">\(\mathbf{B}_{\pi}\)</span>的不动点。</p>
<p>根据Contraction Mapping​ Theorem，对任何值函数<span class="math inline">\(\mathbf v\)</span>都有</p>
<p><span class="math display">\[\lim_{N \to \infty} \mathbf{B}_{\pi}^{N} \mathbf{v}=\mathbf{v}_{\pi}\]</span></p>
<p>这保证了我们可以从一个随机的起点出发，不断按照Bellman方程更新值函数<span class="math inline">\(\mathbf v\)</span>，从而收敛到<span class="math inline">\(\mathbf{v}_{\pi}\)</span>。</p>
<h2 id="policy-improvement">Policy Improvement</h2>
<p>接下来我们分析策略提升的过程。</p>
<p>在第<span class="math inline">\(k\)</span>次迭代中，我们计算得到了当前的策略<span class="math inline">\({\pi_{k}}\)</span>，对这个策略进行策略评估，我们得到相应的值函数 <span class="math display">\[\mathbf{V}_{\pi_{k}}\]</span>。</p>
<p>那么策略提升的过程就是令<span class="math inline">\(\pi_{k+1}\)</span>满足</p>
<p><span class="math display">\[\pi_{k+1}=G\left(\mathbf{v}_{\pi_{k}}\right)\]</span></p>
<p>现在我们想证明存在<span class="math inline">\(\pi_{k+1} \geq \pi_{k}\)</span>，从而保证策略提升一定会让策略变得更好。</p>
<p>还记得我们之前说</p>
<p><span class="math display">\[\mathbf{B}_{G(\mathbf{v})}\mathbf{v}=\mathbf{B}_{*} \mathbf{v}\]</span></p>
<p>于是有</p>
<p><span class="math display">\[\mathbf{B}_{*}\mathbf{v}_{\pi_{\mathbf{k}}}=\mathbf{B}_{G\left(\mathbf{v}_{\pi_{\mathbf{k}}}\right)} \mathbf{v}_{\pi_{\mathbf{k}}}=\mathbf{B}_{\pi_{k+1}} \mathbf{v}_{\pi_{\mathbf{k}}}\]</span></p>
<p>根据定义，显然对所有对值函数<span class="math inline">\(\mathbf v\)</span>有<span class="math inline">\(\mathbf{B}_{*} \mathbf{v} \geq \mathbf{B}_{\pi} \mathbf{v}\)</span>，于是</p>
<p><span class="math display">\[\mathbf{B}_{*}\mathbf{v}_{\pi_{k}} \geq \mathbf{B}_{\pi_{k}} \mathbf{v}_{\pi_{k}}=\mathbf{v}_{\pi_{k}}\]</span></p>
<p>结合上面的式子得到</p>
<p><span class="math display">\[\mathbf{B}_{\pi_{k+1}}\mathbf{v}_{\pi_{\mathbf{k}}} \geq \mathbf{v}_{\pi_{\mathbf{k}}}\]</span></p>
<p>这说明对值函数进行<span class="math inline">\(\mathbf{B}_{\pi_{k+1}}\)</span>算子的运算是一个单调递增的过程，也就是说</p>
<p><span class="math display">\[\mathbf{B}_{\pi_{k+1}}^{N}\mathbf{v}_{\pi_{\mathbf{k}}} \geq \ldots \mathbf{B}_{\pi_{k+1}}^{2} \mathbf{v}_{\pi_{\mathbf{k}}} \geq \mathbf{B}_{\pi_{k+1}} \mathbf{v}_{\pi_{\mathbf{k}}} \geq \mathbf{v}_{\pi_{\mathbf{k}}}\]</span></p>
<p>而又有</p>
<p><span class="math display">\[\mathbf{v}_{\pi_{\mathrm{k}+1}}=\lim_{N \to \infty} \mathbf{B}_{*}^{N} \mathbf{v}_{\pi_{\mathrm{k}}}=\lim _{N \to \infty} \mathbf{B}_{\pi_{k+1}}^{N} \mathbf{v}_{\pi_{\mathrm{k}}}\]</span></p>
<p>于是</p>
<p><span class="math display">\[\mathbf{v}_{\pi_{\mathrm{k}+1}}=\lim_{N \to \infty} \mathbf{B}_{\pi_{k+1}}^{N} \mathbf{v}_{\pi_{\mathrm{k}}} \geq \mathbf{v}_{\pi_{\mathrm{k}}}\]</span></p>
<h2 id="policy-iteration">Policy Iteration</h2>
<p>我们之前完成了策略提升的证明，在第<span class="math inline">\(k + 1\)</span>个策略迭代中，我们可以保证单调，也就是<span class="math inline">\(\mathbf{v}_{\pi_{\mathbf{k}+1}} \geq \mathbf{v}_{\pi_{\mathbf{k}}}\)</span>。</p>
<p>于是，当<span class="math inline">\(\mathbf{v}_{\pi_{\mathbf{k}+1}}=\mathbf{v}_{\pi_{\mathbf{k}}}\)</span>，我们就找到了<span class="math inline">\(\mathbf{v}_{*}\)</span>，这是因为<span class="math inline">\(\mathbf{v}_{*} \geq \mathbf{v}_{\pi}\)</span>，同时<span class="math inline">\(\mathbf{B}_{*}\)</span>又只有一个不动点。</p>
<h2 id="value-iteration">Value Iteration</h2>
<p>Value Iteration的思想就是干脆绕开<span class="math inline">\(\mathbf B_\pi\)</span>，直接让<span class="math inline">\(\mathbf B_*\)</span>参与运算。</p>
<p>因为我们知道<span class="math inline">\(\mathbf{B}_{*}\)</span>有唯一的不动点<span class="math inline">\(\mathbf{v}_{*}\)</span>满足<span class="math inline">\(\mathbf{B}_{*} \mathbf{v}_{*}=\mathbf{v}_{*}\)</span>，而<span class="math inline">\(\mathbf{B}_{*} \mathbf{v}\)</span>又是一个单调递增的运算，因为对于任意的值函数<span class="math inline">\(\mathbf v\)</span>，有</p>
<p><span class="math display">\[\lim_{N \to \infty} \mathbf{B}_{*}^{N} \mathbf{v}=\mathbf{v}_{*}\]</span></p>
<p>这保证了值迭代的可行性。</p>
<h2 id="greedy-policy-from-optimal-vf-is-an-optimal-policy">Greedy Policy from Optimal VF is an Optimal​ Policy</h2>
<p>最后要证明的是Greedy Policy from Optimal VF is an Optimal​ Policy。</p>
<p>其实很简单了，我们已经得到了最优值函数<span class="math inline">\(\mathbf v_*\)</span>，我们贪心的选择策略，也就是</p>
<p><span class="math display">\[\pi_*= G(\mathbf v_*)\]</span></p>
<p>那么根据最优值函数的定义，我们只需要反过来证明<span class="math inline">\(\mathbf v_{\pi_*}= \mathbf v_*\)</span>即可。</p>
<p>首先我们有</p>
<p><span class="math display">\[\mathbf{B}_{G\left(\mathbf{v}_{*}\right)}\mathbf{v}_{*}=\mathbf{B}_{*} \mathbf{v}_{*}\]</span></p>
<p>因<span class="math inline">\(\mathbf v_*\)</span>是不动点，因此满足</p>
<p><span class="math display">\[\mathbf{B}_{G\left(\mathbf{v}_{*}\right)}\mathbf{v}_{*}=\mathbf{B}_{*} \mathbf{v}_{*} = \mathbf{v}_{*}\]</span></p>
<p>这意味着<span class="math inline">\(\mathbf{v}_{*}\)</span>也是<span class="math inline">\(\mathbf{B}_{G\left(\mathbf{v}_{*}\right)}\)</span>的不动点。而<span class="math inline">\(\mathbf{B}_{G\left(\mathbf{v}_{*}\right)}\)</span>又只有一个不动点<span class="math inline">\(\mathbf{v}_{G\left(\mathbf{v}_{*}\right)}\)</span>，因此</p>
<p><span class="math display">\[\mathbf{v}_{*}=\mathbf{v}_{G\left(\mathbf{v}_{*}\right)}\]</span></p>
<p>即</p>
<p><span class="math display">\[\mathbf {v}_{\pi_*}= \mathbf v_*\]</span></p>
]]></content>
      <categories>
        <category>学术</category>
      </categories>
      <tags>
        <tag>强化学习</tag>
        <tag>数学证明</tag>
        <tag>MDP</tag>
      </tags>
  </entry>
  <entry>
    <title>记录一下最近的生活</title>
    <url>/2020/12/14/%E8%AE%B0%E5%BD%95%E4%B8%80%E4%B8%8B%E6%9C%80%E8%BF%91%E7%9A%84%E7%94%9F%E6%B4%BB/</url>
    <content><![CDATA[<p>单纯是记录一下最近的（摸鱼）生活……</p>
<a id="more"></a>
<p>昨天晚上和今天早上下了南京的初雪！</p>
<p><img src="https://franktian-blog.oss-cn-beijing.aliyuncs.com/img/南京的初雪.jpg"></p>
<p>不过拍的不是很好就是啦……</p>
<p>以及，上周末还去了栖霞山，虽然感觉不怎么样hhhh</p>
<p>上山的红叶</p>
<p><img src="https://franktian-blog.oss-cn-beijing.aliyuncs.com/img/栖霞山的红叶.jpg"></p>
<p><img src="https://franktian-blog.oss-cn-beijing.aliyuncs.com/img/栖霞山的红叶2.jpg"></p>
<p>以及学校的黄叶</p>
<p><img src="https://franktian-blog.oss-cn-beijing.aliyuncs.com/img/学校的黄叶.jpg"></p>
<p><img src="https://franktian-blog.oss-cn-beijing.aliyuncs.com/img/南园教学楼.jpg"></p>
<p>还有不小心入镜的我</p>
<p><img src="https://franktian-blog.oss-cn-beijing.aliyuncs.com/img/不小心入镜的我.jpg"></p>
]]></content>
      <tags>
        <tag>日常</tag>
        <tag>生活</tag>
      </tags>
  </entry>
  <entry>
    <title>这个网站被开通了</title>
    <url>/2020/12/08/%E8%BF%99%E4%B8%AA%E7%BD%91%E7%AB%99%E8%A2%AB%E5%BC%80%E9%80%9A%E4%BA%86/</url>
    <content><![CDATA[<p>用了一堆奇奇怪怪的技术让我闲置了小半年的服务器和域名发挥余热。准备这段时间把知乎和其他地方的文章陆陆续续整理过来，算是做个汇总。</p>
<a id="more"></a>
<p>网站现在被托管在阿里云的一个小服务器上，人生第一次见到一核的CPU，还以为htop出bug了。考虑有机会把它搞到自己的机器上，不过要等我分到一个固定ip再说。说起来，最近看到一个想法， 说可以把域名直接映射到ipv6上，然后分配ipv6，这样就省去DNS服务了，amazing。</p>
<p>同时，这个网站还被我同步到了github page和gitee page，具体的教程应该在下一篇文章，两个网站的网址是franktiantt.github.io和franktian424.gitee.io。</p>
<p>就这样吧。</p>
]]></content>
      <categories>
        <category>唠嗑</category>
      </categories>
      <tags>
        <tag>开张撒花</tag>
        <tag>白嫖</tag>
      </tags>
  </entry>
  <entry>
    <title>Transmission服务器端搭建</title>
    <url>/2021/01/13/Transmission%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%AB%AF%E6%90%AD%E5%BB%BA/</url>
    <content><![CDATA[<p>我把闲置的服务器用来做种了，做种的文件放在另一块硬盘中，远程用浏览器监控Transmission的运行情况。</p>
<p>所以需要折腾的技术有以下几部分：</p>
<ul>
<li>把硬盘格式化，自动挂载，修改权限</li>
<li><p>更改Transmission的设置，把负责做种的账户改成自己</p></li>
<li><p>更改Transmission的设置，允许远程访问。</p></li>
</ul>
<p>改Transmission的设置遇到的坑我真是数都数不过来。。。</p>
<a id="more"></a>
<h2 id="硬盘挂载">硬盘挂载</h2>
<p>使用<code>df</code>和<code>du</code>两个指令查看磁盘的情况，可以查看RetHat官方的<a href="https://www.redhat.com/sysadmin/du-vs-df">文章</a>（复习的时候看到RetHat的商业模式是免费试用，付费咨询，老增值模式了）。</p>
<p>简单来说<code>df</code>是<code>disk free</code>，查看磁盘的<strong>大小</strong>，<strong>使用</strong>和<strong>剩余</strong>。通常使用<code>df -h</code>，可以把字节以”方便人类阅读“的形式展现。</p>
<p><code>du</code>是<code>disk usage</code>，更多用来查看子目录的使用情况。</p>
<p>当然，这是针对挂载了的硬盘而言的，我就是查看之后发现我的硬盘容量岌岌可危才打算在机械硬盘上做种的。</p>
<p>用<code>fdisk</code>指令查看所有的磁盘情况。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo fdisk -l</span><br></pre></td></tr></table></figure>
<p>我的服务器上有两块空闲的磁盘</p>
<figure>
<img src="https://franktian-blog.oss-cn-beijing.aliyuncs.com/img/image-20210113153823441.png" alt="image-20210113153823441"><figcaption>image-20210113153823441</figcaption>
</figure>
<p>一块固态，一块机械。</p>
<p>接下来对硬盘进行分区</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo fdisk /dev/sda</span><br></pre></td></tr></table></figure>
<p>进入硬盘管理模式后，输入<code>n</code>创建新的分区，然后跟着提示走就行。</p>
<p>提示会以此让你选</p>
<ul>
<li>Partition type</li>
<li>Partition number</li>
<li>Frist sector</li>
<li>Last sector</li>
</ul>
<p>最后输入<code>w</code>保存设置。</p>
<p>注意，如果Partition type不能从0开始选，或者Partition number不能从2048开始选，说明你的磁盘可能有其他区。</p>
<p>如果想删除其他分区，同样使用<code>fdisk</code>，然后输入<code>d</code>，之后跟着提示走就行。</p>
<p>分区好了之后要格式化，格式化为<code>ext4</code>格式</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo mkfs -t ext4 /dev/sda</span><br></pre></td></tr></table></figure>
<p>最后新建个文件夹，挂载就行，比如我把机械硬盘挂载在<code>MHD</code>文件夹下</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mkdir MDH</span><br><span class="line">sudo mount /dev/sda ~/MHD</span><br></pre></td></tr></table></figure>
<p>但是这样的缺点是每次开机都要重新手动挂载，我们可以让机器启动时自动挂载。</p>
<p>用<code>blkid</code>获取磁盘的uuid和属性</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo blkid</span><br></pre></td></tr></table></figure>
<p>找到你要挂载的，记住它的uuid，在<code>/etc/fstab</code>添上一行自动挂载的语句</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo vim /etc/fstab</span><br></pre></td></tr></table></figure>
<p>模版是</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">UUID=&#123;你的硬盘的uuid&#125;  /u01  ext4  defaults  1  1</span><br></pre></td></tr></table></figure>
<p>别忘了设着硬盘的所有者为你</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo chown -R frank:frank ~/MHD</span><br></pre></td></tr></table></figure>
<h2 id="transmission用户设置">Transmission用户设置</h2>
<p>安装<code>transmission-daemon</code>，这玩意是transmission的守护进程，它会帮你下载<code>transmission-cli</code>什么的。不过我们配置好了就不需要用命令行了（用命令行做种也太古早了）</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo apt install transmission-daemon</span><br></pre></td></tr></table></figure>
<p>下载好了它就会自动开启，这时候要先关闭它</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo service transmission-daemon stop</span><br></pre></td></tr></table></figure>
<p>把配置文件中的USER改成你自己</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo vim /etc/init.d/transmission-daemon</span><br></pre></td></tr></table></figure>
<p>下面的也是，把USER改成你自己</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo vim /lib/systemd/system/transmission-daemon.service</span><br></pre></td></tr></table></figure>
<p>最后给配置文件的用户改成你自己</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo chown -R frank:frank /etc/transmission-daemon</span><br><span class="line">sudo chown -R frank:frank /var/lib/transmission-daemon/</span><br></pre></td></tr></table></figure>
<p>现在还不能启动，要再把网络权限改一下</p>
<h2 id="transmission远程管理设置">Transmission远程管理设置</h2>
<p>打开<code>/etc/transmission-daemon/settings.json</code></p>
<p>要更改的是下面的内容</p>
<ul>
<li>rpc-username改成远程登录想用的用户名</li>
<li>rpc-password改成远程登录想用的密码</li>
<li>rpc-whitelist改成"*.*.*.*"，或者把rpc-whitelist-enabled改成false</li>
</ul>
<p>这个还有一个坑，似乎是自动挂载的问题，就是它开始可能不会读这个文件的内容，还要改一下<code>~/.config/transmission-daemon/settings.json</code>的内容，把这个cp过去就好了。</p>
<p>注意这个文件的拥有者也要是你自己。</p>
<p>最后，介绍一个很好用的web界面，仓库地址是https://github.com/ronggang/transmission-web-control。</p>
<p>下载releases的版本之后安装就好了。</p>
<h2 id="enjoy">Enjoy!</h2>
<p>打开守护进程</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo service transmission-daemon start</span><br></pre></td></tr></table></figure>
<p>在自己的电脑上打开网页<code>&#123;服务器的ip&#125;:9091</code></p>
<p>Enjoy it!</p>
]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>闲的蛋疼</tag>
        <tag>浪费时间</tag>
        <tag>不务正业</tag>
      </tags>
  </entry>
</search>
